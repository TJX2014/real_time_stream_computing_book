## 模型学习和预测
在数据流上进行模型学习并根据模型作出判断或预测，是将统计学习和机器学习的理论和方法推广应用在流数据上的结果。
流数据不断输入模型学习算法，实时更新模型参数，在线训练所得模型能够更加及时和真切地描述当前事态。
比如在实时反欺诈和实时推荐系统这样的场景下，基于流的模型学习发挥着重要的作用。

### 模型的分类
数据研究人员在为数据建模时，有两种非常不同的思路，一种是统计学习模型，另一种是机器学习模型。
统计学习模型以统计分析为基础，偏向于挖掘数据内部产生的机制，更加注重模型和数据的可解释性。
而机器学习模型以各种机器学习方法为基础，偏向于用历史数据来预测未来数据，更加注重模型的预测效果。
我们分别从统计学习角度和机器学习角度来讨论实时流数据模型学习和预测的问题。


#### 统计学习模型
在使用统计学习模型来建模时，最主要的问题在于确定随机变量的概率分布函数或概率密度函数。
常见的离散型随机变量分布模型有"0-1分布"、二项分布、多项式分布和泊松分布等。
常见的连续型随机变量分布模型则有均匀分布、正态分布和指数分布等。
在传统针对离线批数据做统计分析时，所建模型重要目标是解释既有的数据。
建模得到的分布参数是不变的，比如高斯分布的期望和方差、泊松分布的期望等。
但是在针对流数据进行统计建模时，虽然确定分布参数依旧固然重要，但分布的参数却可能随着时间流逝而发生着变化。
一个很常见的例子就是，一家商店晚上的客流量一般会比早上多，而周末的客流量也会比工作日的客流量多。
如果我们用柏松分布来对每小时的客流量建模，那很明显这个柏松分布的期望是随着时间在变化的。
所以当在实时流上构建统计学习模型时，模型通常会包含两层，
一层是随机变量在一段时间窗口内的概率分布函数，另一层是概率分布函数的参数是随时间变化的变量。
比如考虑了期望随时间变化的柏松分布就需要重新定义为：
```
P(X=k|lambda(t)) = lambda(t)^k / k! * e^(-lambda(t)), k=0,1,... 
```
其中lambda(t)是当前时刻对lambda值的估计。那具体怎样估计这个lambda估计值呢？
估计lambda本身比较简单，因为对于柏松分布，其lambda值就是期望的无偏估计。
稍微有所需要考虑的是应该怎样更新这个估计值。可以有两种更新方式。
1、逐事件更新，也就是每来一个新数据就重新估计一次。
2、定周期更新，也就是每隔一段时间重新估计一次，比如每小时重新估计一次。
两种方式都是不错的选择，可以根据具体业务场景需要以及是否能够满足实时计算的性能要求作出合适选择。


##### P-value检验
在传统的统计检测中，P-value检验是非常重要的手段。
以小明和小花抛硬币打赌为例，小花赌"字"朝上，小明赌"花"朝上。
小明从口袋拿出一个硬币抛了1次，结果是"花"朝上。小花不服，要求再来一局。。。
在反反复复抛了10次后，总共有9次"花"向上，只有1次"字"向上。
对于这个结果，小花更加不服气了，觉得小明的硬币一定是个"假"硬币。
那怎样科学地判断小明的硬币是否是"假"硬币呢？这里就可以用到P-value检验的方法。
首先，我们假定硬币是"真"的，也就是"字"朝上和"花"朝上的概率都是0.5，
那么抛10次硬币只有不超过1次"字"向上的概率就是
C(10,0) * 0.5^0 * (1-0.5)^10 + C(10,1) * 0.5^1 * (1-0.5)^9 = 11 / 1024 = 0.0107。
这么一算，只有百分之一的概率，小花当然可以理直气壮地怀疑小明对硬币做了手脚。
在上面的这个例子中，0.0107就是所谓的P-value。由于P-value很小，故而可以推翻我们前面的"真"硬币假设。

而当把统计学习模型应用在在线系统的异常检测时，P-value又有了一层新的含义。
考虑统计PV(page view，页面浏览量)的场景。
根据过往经验和离线历史数据的统计，我们认为某个页面每秒钟的访问次数应该符合期望为6的泊松分布分布。
可是实时流计算系统的统计结果却显示当前一秒这个页面的访问量竟然达到了16次。
那这是正常流量波动还是系统受到了攻击？根据柏松分布的概率密度函数，计算得到：P(X>=16)=0.00050。
这个概率很小，意味着这秒的页面访问量和我们的预期并不相符。但此时我们并不是像之前P-value检验中那样拒绝假设，
而是反过来断定一秒种16次的访问量是异常行为，这也预示着我们的系统可能正受到攻击。


#### 机器学习模型
使用机器学习的方法构建模型有个极大的好处，即我们不需要对数据内在的产生机理有任何的先验知识。
基本上只需要准备好模型使用的特征，确定要最优化的目标函数（也就是具体的机器学习模型），
就可以让机器去自动发现数据中潜在的产生模式，并对未知的数据作出预测。
常见的机器学习模型有线性回归、逻辑回归、朴素贝叶斯、神经网络、决策树和随机森林等。
下面我们就以线性回归为例，初步介绍机器学习模型在流数据上是如何进行学习和预测的。

##### 线性回归模型
流数据天然就是时间序列的一种表现形式。
时间序列分析的重要目标之一，是用历史序列来预测未来，比如环境温度、股价和网站流量等等。
现在我们就尝试下用线性回归模型来预测下一个交易日的上证指数。
以2003年全年的上证指数收盘价构成时间序列，我们的目标是用最近10个交易日收盘价预测下一个交易日的收盘价。
所以线性回归模型的输入就是最近10个交易日的收盘价，而输出则是下一个交易日的收盘价。

```
int numberOfVariables = 10;
UpdatingMultipleLinearRegression rm = new MillerUpdatingRegression(numberOfVariables, true);
Queue<Double> xPrices = new LinkedList<>();
double[] predictPrices = new double[prices.length];
for (int i = 0; i < prices.length; i++) {
    double price = prices[i];

    // numberOfVariables not enough, so pass and continue
    if (i < numberOfVariables) {
        xPrices.add(price);
        predictPrices[i] = 0;
        continue;
    }

    if (i <= numberOfVariables * 2 + 1) {
        // observations not enough, so pass and continue
        predictPrices[i] = 0;
    } else {
        // predict according model
        double params[] = rm.regress().getParameterEstimates();
        List<Double> xpList = new LinkedList<>();
        xpList.add(1d);
        xpList.addAll(xPrices);
        double[] x_p = ArrayUtils.toPrimitive(xpList.toArray(new Double[0]));
        double y_p = new ArrayRealVector(x_p).dotProduct(new ArrayRealVector(params));
        predictPrices[i] = y_p;
    }

    // update model
    double[] x = ArrayUtils.toPrimitive(xPrices.toArray(new Double[0]));
    double y = price;
    rm.addObservation(x, y);
    xPrices.add(price);
    xPrices.remove();
}
```
在上面的代码中，使用了能够增量更新训练的线性回归模型实现`MillerUpdatingRegression`。
按照时间顺序，依次将每天的收盘价price和前10个交易日的收盘价`xPrices`分别作为线性回归模型的因变量y和自变量x，
形成一组观察记录，通过`addObservation`方法更新到模型中去。
另外，使用`regress`函数获得当前训练所得线性回归模型的参数，
再结合过去10个交易日的收盘价`xPrices`即可求得收盘价的预测值`y_p`。

下图是上证指数预测值与真实值的对比。从图中可以看出，预测收盘价曲线能够比较好地跟随真实收盘价曲线变化的趋势，
但是却并不能非常好地预测真实收盘价曲线的突变。所以整体看来，预测收盘价曲线总是比真实收盘价曲线慢半拍。
这也意味着，我们并不能指望用这个线性回归模型从上证指数的变化中获利。

当然，这里用线性回归模型预测上证指数只是一个演示性质的例子。
如果我们把上证指数换成其它概念，比如网站流量、环境温度等，就可以将同样的方法推广应用到其它更适合线性回归模型的场景。

#### 在线模型学习的限制
1. 只有少部分的模型能够实现增量更新，相比批处理中的训练算法在实现起来也更加困难，这也导致开箱即可用的开源软件并不多。
2. 如果将模型的学习和预测耦合在一起，会极大地拖慢在线系统处理速度。
3. 实际生产中模型上线前，一方面要验证和评估模型效果，另一方面要尽可能地解释训练所得模型，单纯地在线更新模型并不适合这种场景。
4. 在线模型学习算法实现起来更加复杂，对性能要求也更加敏感，需要数据团队和工程团队更加密切的配合。
对大部分公司而言，让开发任务尽量解耦可能是更现实的做法。
